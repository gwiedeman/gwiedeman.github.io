## Data Analytics Approaches for Web Archives

Gregory Wiedeman<br/>
University Archivist<br/>
M.E. Grenander Department of Special Collections & Archives

---

<!-- .slide: data-background="img/stacks.jpg" -->

---

<!-- .slide: data-background="img-iipc/undergradBulletin.png" -->

---

## Collecting the Web at UAlbany

* Preserve and manage permanent public records
* Crawling and preserving albany.edu since 2012
* Began outside collecting in 2016
* 1.5 TB of Web Data
* Collect, preserve, provide access, and encourage use

---

<!-- .slide: data-background="img/docnow.png" -->

---

## Twitter Data

* Detecting Russian bots: it`s
* Ed Summers [apostrophe dataset](https://github.com/edsu/apostrophe) 40 accounts
* Collected 14,217 tweets with [Twarc](https://github.com/DocNow/twarc)

<img src="img/botTweets.png"/>

---

<!-- .slide: data-background="img/botClouds.jpg" -->

---

## Challenges of Working with WARCS

* .warc file ISO standard
* Tremendous volume of data
* Mess of HTML, CSS, JavaScript
* Unclear provenance

---

Jonathan Albright

---

## Tools are getting easier

* [Archives Unleashed Toolkit](https://github.com/archivesunleashed/aut)
* [Warclight](https://github.com/archivesunleashed/warclight)

---

* 8595 of 10649 URLs were still live
* 81%

---

# How to Collect